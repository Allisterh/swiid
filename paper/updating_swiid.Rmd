---
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: false
    fig_caption: true
    latex_engine: pdflatex
    template: svm-latex-ms2.tex
title: "Measuring Income Inequality Across Countries and Over Time: The Standardized World Income Inequality Database [DRAFT]"
thanks: "The paper's revision history and the materials needed to reproduce its analyses can be found [on Github here](http://github.com/fsolt/swiid). Corresponding author: [frederick-solt@uiowa.edu](mailto:frederick-solt@uiowa.edu). Current version: `r format(Sys.time(), '%d %B %Y')`."
author:
- name: Frederick Solt
  affiliation: University of Iowa
abstract: "_Objective_:_Methods_:_Results_:_Conclusion_:"
keywords: "income inequality, measurement"
date: "`r format(Sys.time(), '%B %d, %Y')`"
fontsize: 11pt
spacing: single
bibliography: \dummy{`r file.path(getwd(), list.files(getwd(), "d\\.bib$"))`}
biblio-style: apsr
citecolor: black
linkcolor: black
endnote: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=6.5, fig.height=2)
library(tidyverse)
```

## Introduction

<!--Obviously this section needs work

# From its origins now over ten years ago, the goal of the [Standardized World Income Inequality Database](/swiid/) has been to provide estimates of income inequality for as many countries and years as possible while ensuring that these estimates are as comparable as the available data allow.
# That is to say, the SWIID's first prority is breadth of coverage, and its second is comparability.
# The starting point for the SWIID estimates is a dataset with the complementary priorities: the [Luxembourg Income Study](https://www.lisdatacenter.org), which aims to maximize comparability and, given that primary concern, to include as many countries and years as possible.^[
# Still, even for the LIS perfect comparability has given way to the desire to cover more middle-income countries.
# [Teresa Munzi and Andrej Cupak recently wrote](https://www.lisdatacenter.org/newsletter/nl-2018-8-h-2/) about the difficulties the LIS team  encountered including middle-income countries due to the greater importance of non-monetary and self-employment income as well as the differences in direct taxation and social security contributions in these countries in comparison to high-income countries.
# Despite these issues, the LIS remains the most comparable income inequality data available.]
# Then the SWIID routine estimates the relationships between Gini indices based on the LIS and [all of the other Ginis available](/blog/2017/07/28/the-swiid-source-data/) for the same country-years, and it uses these relationships to estimate what the LIS Gini _would be_ in country-years not included in the LIS but available from other sources.-->


```{r data-setup, include=FALSE}
api <- c("LISSY", "CEPAL", "OECD", "Eurostat", "Beegle et al. 2016", "Statistics Canada", "Statistics Denmark", "Statistics Finland", "CSO Ireland", "Statistics Norway", "Statistics Sweden")
sheet <- c("SEDLAC", "Transmonee 2012", "Personal communication, K. Beegle, 2016-08-01", "World Bank Povcalnet", "Australian Bureau of Statistics", "Instituto Naciónal de Estadística de Bolivia", "Instituto de Pesquisa Económica Aplicada", "DANE Colombia", "Instituto Naciónal de Estadística y Censos Costa Rica", "CAPMAS Egypt", "Statistics Estonia", "Statistics Georgia", "Statistics Hong Kong 2017", "Statistics Indonesia", "Istat", "Statistical Institute of Jamaica", "Kazakhstan Committee on Statistics", "Statistics Korea", "National Statistical Committee of Kyrgyzstan", "National Bureau of Statistics of Moldova", "Statistical Office of Montenegro", "Statistics New Zealand 1999", "Philippines Statistical Agency", "Russian Federal State Statistics Service", "Singapore Department of Statistics", "Slovenia Statistics Office", "Slovenia Statistics Office 2005", "Instituto Nacional de Estadística Spain", "Switzerland Federal Statistics Office", "Taiwan Directorate General of Budget, Accounting, and Statistics", "Turkish Statistical Institute", "UK Office for National Statistics", "Institute for Fiscal Studies", "U.S. Congressional Budget Office", "U.S. Census Bureau", "Instituto Nacional de Estadística Venezuela", "Milanovic 2016", "Milanovic 2016; Brandolini 1998", "Ackah, Bussolo, De Hoyos, and Medvedev 2008")
pdf <- c("National Statistical Service of Armenia", "Belarus National Committee of Statistics", "Statistics Hong Kong 2012", "Statistics Hong Kong 2007", "Dirección General de Estadística, Encuestas y Censos 2016", "Economy Planning Unit of Malaysia", "Perry 2018", "Dirección General de Estadística, Encuestas y Censos 2017", "Statistics Sri Lanka 2015", "NESDB Thailand", "Instituto Nacional de Estadistica Uruguay", "General Statistics Office of Vietnam 2013", "General Statistics Office of Vietnam")
scrape <- c("Insee France", "Statistical Center of Iran", "National Statistical Office of Thailand")

length(api) <- length(sheet)
length(pdf) <- length(sheet)
length(scrape) <- length(sheet)

mode <- tibble(api, sheet, pdf, scrape) %>% 
    gather(key = mode, value = source1) %>% 
    filter(!is.na(source1))

swiid_source <- read_csv("https://raw.githubusercontent.com/fsolt/swiid/master/data/swiid_source.csv", 
                         col_types = "cdddcclcccc") %>% 
    left_join(mode, by = "source1") %>% 
    mutate(mode = if_else(is.na(mode), "hand", mode))

wordify_numeral <- function(x) setNames(c("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen", "sixteen", " seventeen", "eighteen", "nineteen"), 1:19)[x]

api_percent <- swiid_source %>% count(mode == "api") %>% mutate(p = round(n/nrow(swiid_source) * 100)) %>% filter(`mode == "api"` == TRUE) %>% pull(p)

automated_percent <- swiid_source %>% count(mode == "hand") %>% mutate(p = round(n/nrow(swiid_source) * 100)) %>% filter(`mode == "hand"` == FALSE) %>% pull(p)

single_obs_countries <- swiid_source %>% add_count(country) %>% filter(n == 1) %>% nrow() %>% wordify_numeral()

```


## Collecting the SWIID Source Data

The SWIID source data consists of observations of the Gini coefficient in various countries and years.^[
Because the Gini index is simply the Gini coefficient multiplied by 100, the two are equivalent, and both can be referred to as 'the Gini' without much cause for confusion.]
The Gini is most intuitively defined as the average difference in income between all pairs in a population, divided by twice the average income in the population.
It is by far the most commonly encountered summary statistic for measuring income inequality.
The Gini has drawbacks---it is most sensitive to changes in the middle of the income distribution, rather than among those with the highest or lowest incomes, and it is not easily decomposed---that other metrics, such as the Atkinson index and the Theil indices, overcome.
However, in light of the SWIID's goal of providing data for the broadest possible sample of countries and years, the ubiquity of the Gini makes it the only plausible choice for this purpose.

To be included in the SWIID source data, Gini observations need to encompass the entire population of a country without regard to age, location, or employment status.^[
The requirement for complete territorial coverage was relaxed for minor deviations such as data on Portugal that excludes Madeira and the Azores.
It was relaxed somewhat further for early series that covered only the urban population of three highly urbanized countries: Uruguay, Argentina, and South Korea.
The general rule, however, is that data is excluded if it measures the income distribution of only urban or rural populations, or of only selected cities, or some other such incomplete territory.
This requirement that the observation must not be restricted to only the employed is new; it means nearly 600 observations on the distribution of wages across employed individuals that were included in the source data of earlier versions of the SWIID are now excluded.
Between the lack of information on those out of the workforce and on how workers formed households, these data were not very strongly related to LIS data on income inequality in the entire population anyway.]
They need to have an identifiable welfare definition and equivalence scale (more on these below). 
Finally, to ensure that these original sources are easily available to SWIID users, observations need to be available online, although not necessarily without paywalls.^[
For scholarly articles, DOIs or JSTOR stable URLs were the preferred web addresses, but if those were unavailable the publisher's website or another repository was used.
For books, the link is to the relevant page in Google Books.]

```{r data_by_method, echo=FALSE, fig.cap = "\\label{fig:data_by_method}Income Inequality Observations by Method of Collection"}

swiid_source %>% 
  count(mode) %>% 
  mutate(method = fct_recode(factor(mode), 
                             API = "api",
                             Spreadsheet = "sheet",
                             PDF = "pdf",
                             Webscrape = "scrape",
                             Manual = "hand") %>% 
           fct_relevel("API", "Spreadsheet", "PDF", "Webscrape", "Manual")) %>% 
  ggplot(aes(method, n)) +
geom_bar(stat="identity") +
    theme_bw() +
    theme(axis.title.x = element_blank()) +
    ylab("Observations")
```

Hand-entering data is tedious and error-prone work, so I automated as much of the process of data collection as practicable.
Most international organizations and a few national statistical offices use application programming interfaces (APIs) that facilitate downloading their data, and often the R community has built packages using these APIs to make the task even easier [see @Magnusson2014; @Lahti2017; @Lugo2017; @Blondel2018; @Wickham2018].
I took as much advantage of these resources as possible, as shown in Figure&nbsp;\ref{fig:data_by_method}.
Although the sources with APIs were relatively few, they contained the most data: `r api_percent`% of the observations were collected this way.
In the absence of an API, I scripted downloading and reading any available spreadsheets [see @Wickham2016a].
If there was no spreadsheet, but data were available in pdf files, I automated downloading these files and then used the `tabulizer` package [@Leeper2016] to read the tables into R.
In the rare absence of any file to download, I scripted the process of scraping the data from the web.^[
Code for the entire process can be viewed here: <https://github.com/fsolt/swiid/blob/master/R/data_setup.R>.]
Still, for a variety of reasons, a source's data may have been consigned to being entered in a separate spreadsheet.^[
See <https://github.com/fsolt/swiid/blob/master/data-raw/fs_added_data.csv>.]
Many sources contain just a handful or fewer observations, making the payoff to the often laborious process of data cleaning too small to justify the effort.
Some sources---including most academic articles---are behind paywalls, making reproducibility particularly challenging in any event.
Other sources, such as many books, cannot be read directly into R.
Finally, one source contains crucial information encoded in the typeface of its tables [see @Mitra2006, 6], information lost when the tables are read directly into R.
All of the entries in this spreadsheet were checked repeatedly for errors, and I excluded repeated reports of the exact same observation from different sources.^[
Which, of course, is not to say that these entries are error-free.
If you spot any problems or know of sources I might have missed, _please_ let me know at <https://github.com/fsolt/swiid/issues/6>.]

In the end, I was able to automate the collection of `r automated_percent`% of the source data and an even higher percentage of the observations that will be updated or are subject to revision, greatly facilitating incorporating these changes in future versions.

```{r data_by_coverage, echo=FALSE, fig.cap = "Income Inequality Datasets by Country-Years Covered \\label{data_by_coverage}"}
atg_cy <- haven::read_dta(here::here("data-raw", "atg.dta")) %>% 
    select(country, year, starts_with("gini")) %>% 
    mutate(has_gini = rowMeans(select(., starts_with("gini")), na.rm = TRUE)) %>% 
    filter(has_gini > 0) %>% 
    count(country, year) %>% 
    nrow()

wider_cy <- readxl::read_excel(here::here("data-raw", "WIID_19Dec2018.xlsx")) %>% 
    filter(areacovr == "All" & popcovr == "All" & areacovr == "All" &
               !is.na(gini_reported) &
               !is.na(resource) &
               !is.na(scale) &
               !(resource == "Earnings")) %>% 
    select(country, year, gini_reported, source, resource, scale, everything()) %>% 
    count(country, year) %>% 
    nrow()

ss_cy <- swiid_source %>%
    count(country, year) %>%
    nrow()

datasets <- c("Eurostat", "OECD", "SEDLAC", "LISSY", "CEPALStat", "World Bank Povcalnet")

cy_coverage <- swiid_source %>% 
    count(source1, country, year) %>%
    count(source1, name = "n_cy") %>% 
    filter(source1 %in% datasets) %>% 
    mutate(source1 = recode(source1, LISSY = "LIS", "World Bank Povcalnet" = "Povcalnet")) %>% 
    bind_rows(tibble(source1 = c("WIID", "All the Ginis", "SWIID Source"),
                     n_cy = c(wider_cy, atg_cy, ss_cy))) %>% 
    arrange(desc(n_cy))

ggplot(cy_coverage, aes(forcats::fct_reorder(source1, n_cy, .desc = TRUE), n_cy)) +
    geom_bar(stat="identity") +
    theme_bw() +
    theme(axis.title.x = element_blank()) +  
    ylab("Country-Years") +
    ggtitle("Income Inequality Datasets by Country-Years Covered")
```

The resulting dataset comprises `r swiid_source %>% nrow() %>% scales::comma()` Gini coefficients from `r swiid_source %>% count(country, year) %>% nrow() %>% scales::comma()` country-years in `r swiid_source %>% count(country) %>% nrow()` countries or territories; as shown in Figure \ref{data_by_coverage}, this makes the coverage of the SWIID source data broader than that of any other income inequality dataset.
This is not surprising given that, with the exceptions of the two other secondary collections---the World Income Inequality Database [@UNU2018], which contains no original data and so is not drawn on at all, and the _All the Ginis_ database [@Milanovic2019], which contains very little original data and so is not drawn on much---the SWIID source data incorporates all of the data in these other datasets.  
Turning from how the source data were collected to how they are composed reveals that there is much more data available about the income distribution in some countries than in others.
Which countries are most data-rich?
Figure \ref{countries_by_obs} below shows the top dozen countries by the count of observations.
Canada, by virtue of the excellent Statistics Canada as well as longstanding membership in the OECD and LIS, has `r nrow(swiid_source %>% filter(country=="Canada"))` observations, many more than any other country.
The United Kingdom, Germany, and the United States are next, followed by a group dominated by European countries but including Mexico, Taiwan, and Brazil.
All of these data-rich countries are members of the LIS.
On the other hand, the `r single_obs_countries` most data-poor countries have only a single observation each in the SWIID source data.

```{r obs_by_country, echo=FALSE, fig.cap = "Countries with the Most Observations in the SWIID Source Data \\label{countries_by_obs}"}
swiid_source %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country)) %>% 
  count(country) %>%
  arrange(desc(n)) %>% 
  head(12) %>% 
  ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank() ) +
  ylab("Observations")

uk_nas <- {max(swiid_source$year) - min(swiid_source$year) - 
{swiid_source %>% filter(country == "United Kingdom") %>% pull(year) %>% unique() %>% length()}} %>%
wordify_numeral()

sweden_nas <- {max(swiid_source$year) - min(swiid_source$year) - 
{swiid_source %>% filter(country == "Sweden") %>% pull(year) %>% unique() %>% length()}} %>%
wordify_numeral()

us_nas <- {max(swiid_source$year) - min(swiid_source$year) - 
{swiid_source %>% filter(country == "United States") %>% pull(year) %>% unique() %>% length()}} %>%
wordify_numeral()

japan_nas <- {max(swiid_source$year) - min(swiid_source$year) - 
{swiid_source %>% filter(country == "Japan") %>% pull(year) %>% unique() %>% length()}} %>%
wordify_numeral()

taiwan_nas <- {max(swiid_source$year) - min(swiid_source$year) - 
{swiid_source %>% filter(country == "Taiwan") %>% pull(year) %>% unique() %>% length()}} %>%
wordify_numeral()

arg_obs <- swiid_source %>% filter(country == "Argentina") %>% pull(year) %>% unique() %>% length()

iran_obs <- swiid_source %>% filter(country == "Iran") %>% pull(year) %>% unique() %>% length()

med_cy <- swiid_source %>% count(country, year) %>% count(country, name = "nn") %>% pull(nn) %>% median() %>% wordify_numeral()
```

As discussed in the next section, observations for the same country in the same year, but with different welfare definitions and equivalence scales or from different sources, are important to generating the SWIID's cross-nationally comparable estimates.
Still, we might be interested to know which countries have the most coverage of the years in the SWIID's current `r max(swiid_source$year) - min(swiid_source$year)`-year timeframe, from `r min(swiid_source$year)` to `r max(swiid_source$year)`, because the SWIID's inequality estimates for countries with fewer country-year observations will include more interpolated values, which in turn will have more uncertainty, and---because estimates are not extrapolated beyond the years observed in the source data---more years without any estimates at all.
The countries with the most observed years are shown in the left panel of Figure \ref{countries_by_years}.
The source data includes observations in every covered year for Sweden and the United Kingdom.  There are observations in all but `r us_nas` years for the United States, and in all but `r japan_nas` years for Japan and Taiwan.
Iran and Argentina---countries that are not members of the LIS---also make the top ten, with observations in `r iran_obs` and `r arg_obs` country-years, respectively.
The median country, though, has observations in just `r med_cy` different country-years.

```{r years_by_country, echo=FALSE, fig.cap="Country-Year Coverage in the SWIID Source Data \\label{countries_by_years}"}
library(patchwork)

cby_plot <- swiid_source %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country)) %>% 
  count(country, year) %>%
  count(country, name = "nn") %>% 
  arrange(desc(nn)) %>% 
  head(12) %>% 
  ggplot(aes(forcats::fct_reorder(country, nn, .desc = TRUE), nn)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95)) +
  ylab("Years Observed")


ybc_plot <- swiid_source %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country)) %>%
  count(country, year) %>%
  count(year, name = "nn") %>%
  ggplot(aes(year, nn)) +
  geom_line() +
  theme_bw() +
  scale_x_continuous(breaks = seq(1960, 2020, 10)) +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95)) +
  ylab("Countries Observed")

cby_plot + ybc_plot
```


We can also get a sense of the breadth of the available income inequality data by turning the question around and asking about the number of countries covered across time.
The right panel of Figure \ref{countries_by_years} shows, for each year, the number of countries for which the SWIID source data includes at least one observation.
There are observations for `r swiid_source %>% filter(year==2005) %>% count(country) %>% nrow()` countries in 2005, the year with the broadest coverage.
Coverage is relatively good in all of the years from 2000 to 2015, with at least 80 countries observed per year, before dropping to `r swiid_source %>% filter(year==2016) %>% count(country) %>% nrow()` countries for 2016 and just `r swiid_source %>% filter(year==2017) %>% count(country) %>% nrow()` for 2017.
Before then, country coverage is pretty thin each year through the 1960s and 1970s and still is not great until the late 1980s.^[
This is partly a result of the decision to insist on sources that are available online, but it's just as well: so little information is available about many of the so-excluded observations on that era that it is hard to have much confidence in them.]

Above I mentioned that to be included in the SWIID source data observations need to have an identifiable welfare definition and equivalence scale; let us now consider these two aspects of the data.
A welfare definition is an answer to the question, this Gini measures the distribution of what?
The four welfare definitions employed in the SWIID source data are market income, gross income, disposable income, and consumption.
Market income is defined as the amount of money coming into the household, excluding any government cash or near-cash benefits, the so-called 'pre-tax, pre-transfer' income.^[
It's important, though, to not think of the distribution of market income as 'pre-government.'
Beyond taxes and transfers, governments seeking to shape the distribution of income have a wide array of 'market-conditioning' or 'predistribution' policy options, with minimum wage regulation and labor policy two obvious examples [see, e.g., @Morgan2013]. 
Moreover, even taxes and transfers can profoundly shape the distribution of market income through 'second-order effects.'
Where robust public pension programs exist, for example, people save less for retirement, leaving many of the elderly without market income in old age and so raising the level of market-income inequality [see, e.g., @Jesuit2010].]
Gross income is the sum of market income and government transfer payments; it is 'pre-tax, post-transfer' income.
Disposable income, in turn, is gross income minus direct taxes: 'post-tax, post-transfer' income.^[
Note that disposable income still does not take into account, on the one hand, indirect taxes such as sales or value-added taxes, or, on the other, public services and indirect government transfers such as price subsidies.
There is very little information available about the distribution of such 'final income,' not much beyond that generated by the impressive work of the Commitment to Equity Institute [see @Lustig2018], so I exclude it from the SWIID source data at least for the time being.]
Consumption does not refer to the money coming into the household at all but rather to the money going out.^[
In previous versions of the SWIID, market and gross income were treated as a single welfare definition, and I am glad to finally be able to split them apart [cf. @Solt2016, 1272].
The consumption welfare definition might now be the most heterogeneous within the SWIID source data, varying considerably in whether and how observations treat expenditures on durable goods.
Another source of differences within a single welfare definition is the extent to which nonmonetary income---such as the value of food grown for the household's own consumption or of housing that the owner occupies---is included.
The SWIID source data include the variable `monetary` that indicates whether any nonmonetary income is taken into account, but at present this information is not incorporated into the classification of welfare definitions.]
As can be seen in the left panel of Figure \ref{wd_es}, in the SWIID source data, Ginis of disposable income are much more common than those using other welfare definitions.

```{r obs_by_wd_es, echo=FALSE, fig.cap="Welfare Definitions and Equivalence Scales in the SWIID Source Data \\label{wd_es}"}
wd_es <- swiid_source %>%
  mutate(value = recode(welfare_def, 
                        disp = "Disposable\nIncome", 
                        market = "Market\nIncome", 
                        gross = "Gross\nIncome",
                        con = "Consumption")) %>% 
  count(value) %>% 
  mutate(key = "Welfare Definition") %>% 
  bind_rows(swiid_source %>%
              mutate(value = recode(equiv_scale, 
                                    hh = "Household", 
                                    pc = "Per Capita", 
                                    sqrt = "Square Root",
                                    oecdm = "OECD\nModified",
                                    ae = "Other Adult\nEquivalent")) %>% 
              count(value) %>% 
              mutate(key = "Equivalence Scale")) %>% 
  mutate(key = forcats::fct_relevel(key, "Welfare Definition"))


ggplot(wd_es, aes(forcats::fct_reorder(value, n, .desc = TRUE), n)) +
  geom_col() +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(size = 7),
        strip.background = element_blank()) +
  facet_grid(~ key, scales = "free_x") +
  ylab("Observations")

```

Equivalence scales are the ways in which the size and composition of a household is incorporated into the calculation of its members' welfare.
On the one hand, these factors can simply be ignored, with all households with the same amount of income or consumption treated as if they enjoy the same level of welfare, regardless of their size.  One can improve on this household 'scale'^[
Quoted because, strictly speaking, nothing is being scaled at all; it's simply treating the household as the unit of analysis.] by dividing the household's income by its number of members, that is, by using a per capita scale.
Although undoubtedly superior to simply looking at households, the per capita scale is not ideal: a household of two members and an income of \$100,000 is better off than one with a single member and \$50,000 due to economies of scale---that is the most important reason why people look for roommates.
There are a variety of ways to try to account for these economies by calculating the number of 'equivalent adults' in the household.
Of the most commonly used adult-equivalent scales, the square-root scale is the most straightforward: one simply divides the household income by the square root of the number of members.
The 'OECD-modified' scale for the number of adult equivalents (which the OECD itself actually does not use, preferring the square-root scale) counts the first adult as 1, all other adults as .5, and each child as .3.
And there are many other adult-equivalent scales, from the 'old OECD' scale (1 for the first adult, 0.7 for each additional adult, and 0.5 for each child) to caloric-requirement-based scales (which are in fact very nearly per capita, as it turns out) to a number of country-specific scales.
In previous versions of the SWIID, all adult-equivalent scales were considered a single category.
Now, the square-root scale and the OECD-modified scale have both been split out, leaving the remaining catch-all adult-equivalent category much smaller.
The right panel of Figure \ref{wd_es} shows how many observations in the SWIID source data use each equivalence scale.

Differences in the welfare definition and the equivalence scale employed constitute the biggest source of incomparability across observations in the source data, and all twenty of the possible combinations are represented.  

<!--I'll take up how we get from these incomparable observations to the SWIID estimates in the next post.  In the meantime, if you'd like to see the source data, you can [download it from here](https://github.com/fsolt/swiid/blob/master/data/swiid_source.csv). -->


## Measuring Income Inequality Comparably


## Evaluating the Comparability of the SWIID's Estimates With Cross-Validation

```{r load_kfold, include = FALSE}
kfold_output <- rio::import("https://github.com/fsolt/swiid/raw/master/data/kfold_output.rda") %>% 
    filter(!is.na(point_diff)) # exclude Luxembourg 1985 (LIS is first data available)
kfold_output_by_country <- rio::import("https://github.com/fsolt/swiid/raw/master/data/kfold_output_by_country.rda") %>% 
    filter(!is.na(point_diff)) # exclude Luxembourg 1985 (LIS is first data available)
```


How can we know if the approach just described actually works?
In previous work, I put the SWIID to the most stringent test that occurred to me: I compared LIS data on country-years that had been included in previously-released versions of the SWIID [@Solt2016, 1277-1278].^[
For the initial kernel of this idea, I remain grateful to participants in the Expert Group Meeting on Reducing Inequalities in the Context of Sustainable Development, Department of Economic and Social Affairs, United Nations, New York, October 24–25, 2013.]
The results were reassuring in some ways---only seven percent of the differences between new LIS observations and old SWIID estimates were statistically significant and larger than two Gini points, a far better record than that achieved by data carefully selected from the UNU-WIDER [-@UNU2014] database or by the _All the Ginis_ dataset adjusted in accordance with its instructions [@Milanovic2013, 8]---but less so in others.
Most disappointingly, only 72% of those differences had 95% confidence intervals that included zero, suggesting that the SWIID's standard errors were often too small.
The new SWIID estimation routine described in the preceding section was written and revised to address these issues, but the difficulty of the work done by the LIS team to add new observations means that those additions do not come quickly enough to allow for continuous testing of the SWIID's revisions.
So, instead, I have drawn on a technique developed in data science and machine learning, _k_-fold cross-validation, to assess the SWIID's progress.

To understand how _k_-fold cross-validation works, it helps to first consider the simpler form of cross-validation in which the available data are first divided into two groups of observations: the _training_ set and the _testing_ set.
The model parameters are then estimated on only the training set.
Finally, these results are used to predict the values of the testing set (that is, again, observations that were not used to estimate the model's parameters).
By comparing the model's predictions against the test set, we avoid overfitting and get a good sense of how well the model performs in predicting other, as yet unknown, data.

Still, that sense may be biased by the exact observations that happened to be assigned to each set.
We can reduce this bias by performing the process repeatedly: this is _k_-fold cross-validation.
The available data are divided into some number _k_ groups.
One at a time, each of the _k_ groups is treated as the testing data, with all other groups forming the training data for estimating the model.
The model's performance is then evaluated by considering how well it predicts _all_ of the groups, and  because every observation is included in the testing data at some point, the process allows us to check whether and for which observations the model is doing particularly poorly.

To provide a first assessment of the SWIID's ability to predict the LIS, I randomly assigned the available LIS observations into groups of three, with an added check to ensure that no group included two observations from the same country.^[
The goal of this exercise is really to assess how well the SWIID works within the LIS countries, so Egypt 2012, the only LIS observation for that country, is excluded from the analysis.  This is because holding out that observation makes Egypt a _non_-LIS country.
What happens when the SWIID is used to predict all of a country's LIS observations at once is discussed below.]
(Because the SWIID routine relies only on relationships observed within-country for the countries included in the LIS, the check that only a single observation from a country be assigned to the test data at a time means that the exact size of the group does not really matter, a point I confirmed in testing.)
The figure below plots the difference between the SWIID prediction generated from this _k_-fold cross-validation and the LIS data for each country-year included in the LIS.  Observations for which the 95% credible interval for this difference includes zero are gray; those for which it doesn't are highlighted in blue. 

```{r kfold_output, echo = FALSE, warning = FALSE, fig.height=3, fig.cap = "\\label{fig:kfold_output}_k_-fold By-Observation Cross-Validation Results"}
k_fold_obs_overall <- round(100 - 100*mean(kfold_output %>% filter(n > 1) %>% pull(problem), na.rm = TRUE))
k_fold_obs_lt1 <- round(100*mean(abs(kfold_output %>% filter(n > 1) %>% pull(point_diff)) < .01, na.rm = TRUE))
k_fold_obs_lt2 <- round(100*mean(abs(kfold_output %>% filter(n > 1) %>% pull(point_diff)) < .02, na.rm = TRUE))

ggplot(kfold_output %>%
         filter(n > 1)) +
  geom_hline(yintercept=0, linetype=2, colour="gray60") +
  geom_pointrange(fatten = .25,
                  size = .25,
                  aes(x = forcats::fct_reorder(cy, point_diff), 
                      y=point_diff*100, 
                      ymin=point_diff*100 - 1.96*100*se_diff,
                      ymax = point_diff*100 + 1.96*100*se_diff,
                      colour = cy_color,
                      alpha = problem)) +
  theme_bw() + 
  theme(legend.position="none") +
  scale_colour_manual(values=c("#354995", "#5E5E5E")) +
  scale_alpha_discrete(range = c(0.4, 1)) +
  labs(x = "", y = latex2exp::TeX("SWIID \\textit{k}-fold Prediction minus LIS")) + 
  theme(panel.grid.minor=element_blank()) +
  scale_y_continuous(breaks=c(-10, -5, -2, -1,  0, 1, 2, 5, 10)) +
  scale_x_discrete(breaks = NULL) 
```

The results show that the SWIID does a very good job of predicting the LIS: the 95% credible interval for the difference between the two includes zero for `r k_fold_obs_overall`% of these observations.
The point estimates for these differences are generally small, with `r k_fold_obs_lt2`% less than 2 Gini points and `r k_fold_obs_lt1`% less than a single Gini point.
It's true that there are a few observations for which the estimated difference is quite large---on the far left of the plot, the SWIID routine underestimated the LIS Gini for Hungary in 1991 by $6 \pm 4$ points, and on the extreme right the SWIID routine overestimated that for Guatemala in 2014 by $7 \pm 4$ points---but there doesn't really seem to me to be much pattern in which countries and years are estimated poorly.

This test, though, really only assesses how well the SWIID predicts LIS-comparable inequality figures in years without LIS data in the (now fifty) countries that are _included in the LIS_.
We can get a better sense of how well the SWIID does predicting countries not covered by the LIS with another cross-validation that, one country at a time, excludes _all_ of the LIS observations for that country.
The results of this test are plotted below. 

```{r kfold_output_by_country, echo = FALSE, warning = FALSE, fig.height=3, fig.cap = "\\label{fig:kfold_output_by_country}_k_-fold By-Country Cross-Validation Results"}
k_fold_by_country_overall <- round(100 - 100*mean(kfold_output_by_country %>% pull(problem), na.rm = TRUE))
k_fold_by_country_lt1 <- round(100*mean(abs(kfold_output_by_country %>% pull(point_diff)) < .01, na.rm = TRUE))
k_fold_by_country_lt2 <- round(100*mean(abs(kfold_output_by_country %>% pull(point_diff)) < .02, na.rm = TRUE))

ggplot(kfold_output_by_country) +
  geom_hline(yintercept=0, linetype=2, colour="gray60") +
  geom_pointrange(size = .25,
                  fatten = .25,
                  aes(x = forcats::fct_reorder(cy, point_diff), 
                      y=point_diff*100, 
                      ymin=point_diff*100 - 1.96*100*se_diff,
                      ymax = point_diff*100 + 1.96*100*se_diff,
                      colour = cy_color,
                      alpha = problem)) +
  theme_bw() + 
  theme(legend.position="none") +
  scale_colour_manual(values=c("#354995", "#5E5E5E")) +
  scale_alpha_discrete(range = c(0.4, 1)) +
  labs(x = "", y = latex2exp::TeX("SWIID By-Country \\textit{k}-fold Prediction minus LIS")) + 
  theme(panel.grid.minor=element_blank()) +
  scale_y_continuous(breaks=c(-20, -15, -10, -5, -2, -1,  0, 1, 2, 5, 10)) +
  scale_x_discrete(breaks = NULL) 
```

Overall, the plot looks very similar to the one above.
With each country's entire run of LIS data being excluded in turn, the 95% credible interval for the difference between the resulting SWIID estimate and the excluded LIS data contains zero `r k_fold_by_country_overall`% of the time.
And here, too, most of the point estimates for these differences are small: `r k_fold_by_country_lt2`% are less than 2 Gini points, and `r k_fold_by_country_lt1`% are less than one Gini point.  

This analysis, though, does point to two areas that are in need of future attention.
The first appears on the far left of the plot above.
There we find that the largest difference is for the sole country-year for Egypt in the LIS---for 2012---which the SWIID routine underestimates by $16 \pm 6$ Gini points.
Egypt is currently the only country in the LIS with just a single country-year observation; given that excluding the one observation is equivalent to excluding all of the country's observations, I skipped omitting it in the first cross-validation.
LIS researchers @Checchi2018 [, 6] report that Egyptian income surveys before 2012 did not include any questions to capture self-employment income, and it is also true that most of the available Ginis for Egypt are based on the distribution of consumption expenditure, which sometimes only loosely track those for the distribution of income (as can be seen in the SWIID source data for, e.g., India).
These factors, however, are present in many non-LIS countries as well.
Finding ways to improve the SWIID routine to address them will be a priority.

The second is that there are two other countries for which the 95% credible interval for the differences between the LIS data and the SWIID routine's estimates for those countries when all of their LIS data are excluded does not contain zero in _any_ of the country's observations: Brazil and Peru.
For Brazil, the cross-validation's estimates of the country's four LIS observations are all too high---by $2.5 \pm 2.1$ Gini points to $3.7 \pm 2.1$ Gini points.
The cross-validation's estimates for Peru's four LIS observations, on the other hand, are all too low---by between $5.0 \pm 3.0$ and $5.4 \pm 3.0$ Gini points.
There is room for improvement here too, and this too will receive continued efforts.

All in all, though, these _k_-fold cross-validation exercises show that the SWIID does a very good job of predicting the LIS, which inspires confidence that the SWIID is indeed maximizing the comparability of income inequality data across countries and over time.

